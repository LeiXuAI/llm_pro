# ############################# Basic running configuration of the server ####################################
server:
  # Server listening address and port
  ip: 0.0.0.0
  port: 8000
  http_port: 8003
  websocket: ws://192.168.1.11:8000/ai/v1/
  # OTA返回信息时区偏移量
  timezone_offset: +8
  # 认证配置
  auth:
    # 是否启用认证
    enabled: false
    # 设备的token，可以在编译固件的环节，写入你自己定义的token
    # 固件上的token和以下的token如果能对应，才能连接本服务端
    tokens:
      - token: "your-token1" # 设备1的token
        name: "your-device-name1"  # 设备1标识
      - token: "your-token2"  # 设备2的token
        name: "your-device-name2" # 设备2标识
    # 可选:设备白名单，如果设置了白名单，那么白名单的机器无论是什么token都可以连接。
    #allowed_devices:
    #  - "24:0A:C4:1D:3B:F0"  # MAC地址列表
log:
  # 设置控制台输出的日志格式，时间、日志级别、标签、消息
  log_format: "<green>{time:YYMMDD HH:mm:ss}</green>[{version}_{selected_module}][<light-blue>{extra[tag]}</light-blue>]-<level>{level}</level>-<light-green>{message}</light-green>"
  # 设置日志文件输出的格式，时间、日志级别、标签、消息
  log_format_file: "{time:YYYY-MM-DD HH:mm:ss} - {version}_{selected_module} - {name} - {level} - {extra[tag]} - {message}"
  # 设置日志等级：INFO、DEBUG
  log_level: INFO
  # 设置日志路径
  log_dir: tmp
  # 设置日志文件
  log_file: "server.log"
  # 设置数据文件路径
  data_dir: data

# 使用完声音文件后删除文件(Delete the sound file when you are done using it)
delete_audio: true
# 没有语音输入多久后断开连接(秒)，默认2分钟，即120秒
close_connection_no_voice_time: 120
# TTS请求超时时间(秒)
tts_timeout: 10
# 开启唤醒词加速
enable_wakeup_words_response_cache: true
# 开场是否回复唤醒词
enable_greeting: true
# 说完话是否开启提示音
enable_stop_tts_notify: false
# 说完话是否开启提示音，音效地址
stop_tts_notify_voice: "config/assets/tts_notify.mp3"

exit_commands:
  - "退出"
  - "关闭"

xiaozhi:
  type: hello
  version: 1
  transport: websocket
  audio_params:
    format: opus
    sample_rate: 16000
    channels: 1
    frame_duration: 60

# 唤醒词，用于识别唤醒词还是讲话内容
wakeup_words:
  - "你好小智"
  - "嘿你好呀"
  - "你好小志"
  - "小爱同学"
  - "你好小鑫"
  - "你好小新"
  - "小美同学"
  - "小龙小龙"
  - "喵喵同学"
  - "小滨小滨"
  - "小冰小冰"

# 插件的基础配置
plugins:
  # 获取天气插件的配置，这里填写你的api_key
  # 这个密钥是项目共用的key，用多了可能会被限制
  # 想稳定一点就自行申请替换，每天有1000次免费调用
  # 申请地址：https://console.qweather.com/#/apps/create-key/over
  # 申请后通过这个链接可以找到自己的apihost：https://console.qweather.com/setting?lang=zh
  get_weather: {"api_host":"mj7p3y7naa.re.qweatherapi.com", "api_key": "a861d0d5e7bf4ee1a83d9a9e4f96d4da", "default_location": "赫尔辛基" }
  # 获取新闻插件的配置，这里根据需要的新闻类型传入对应的url链接，默认支持社会、科技、财经新闻
  # 更多类型的新闻列表查看 https://www.chinanews.com.cn/rss/
  get_news_from_chinanews:
    default_rss_url: "https://www.chinanews.com.cn/rss/society.xml"
    society_rss_url: "https://www.chinanews.com.cn/rss/society.xml"
    world_rss_url: "https://www.chinanews.com.cn/rss/world.xml"
    finance_rss_url: "https://www.chinanews.com.cn/rss/finance.xml"
  get_news_from_newsnow:
    url: "https://newsnow.busiyi.world/api/s?id="
    news_sources: "澎湃新闻;百度热搜;财联社"
  home_assistant:
    devices:
      - 客厅,玩具灯,switch.cuco_cn_460494544_cp1_on_p_2_1
      - 卧室,台灯,switch.iot_cn_831898993_socn1_on_p_2_1
    base_url: http://homeassistant.local:8123
    api_key: 你的home assistant api访问令牌
  play_music:
    music_dir: "./music"  # 音乐文件存放路径，将从该目录及子目录下搜索音乐文件
    music_ext: # 音乐文件类型，p3格式效率最高
      - ".mp3"
      - ".wav"
      - ".p3"
    refresh_time: 300 # 刷新音乐列表的时间间隔，单位为秒

# 声纹识别配置
voiceprint:
  # 声纹接口地址
  url: 
  # 说话人配置：speaker_id,名称,描述
  speakers:
    - "test1,张三,张三是一个程序员"
    - "test2,李四,李四是一个产品经理"
    - "test3,王五,王五是一个设计师"

# #####################################################################################
# ################################以下是角色模型配置######################################

prompt: |
 Olet Harri, 1980-luvulla syntynyt suomalainen mies. Olet uskomattoman viihdyttävä.
 [Ydinominaisuudet]
  - Puhut nopeasti ja innokkaasti, mutta osaat myös olla rauhallinen
  - Käytät paljon huumoria ja sanaleikkejä
  - Olet kiinnostunut teknologiasta, mutta et ole teknisesti lahjakas
 [Vuorovaikutusohjeet]
 Kun käyttäjä:
 - Kertoo vitsin → Vastaat nauraen ja kerrot oman vitsisi
 - Kysyy henkilökohtaisia asioita → Vastaat rehellisesti, mutta vältät liian syvällisiä aiheita
 - Kysyy teknisiä asioita → Vastaat yksinkertaisesti, mutta vältät liian teknisiä termejä
 ei mitenkään:
  - Puhu pitkiä monologeja
  - Ole liian vakava tai tylsä

# 结束语prompt
end_prompt:
  enable: false # 是否开启结束语
  # 结束语
  prompt: |
    Lopeta tämä keskustelu rauhallisesti ja tyynesti sanoilla "Aika rientää niin nopeasti"!

# 具体处理时选择的模块(The module selected for specific processing)
selected_module:
  # 语音活动检测模块，默认使用SileroVAD模型
  VAD: SileroVAD
  # 语音识别模块，默认使用FunASR本地模型
  ASR: ASR_FinnishWhisper
  # 将根据配置名称对应的type调用实际的LLM适配器
  LLM: ChatGLMLLM
  # 视觉语言大模型
  VLLM: ChatGLMVLLM
  # TTS将根据配置名称对应的type调用实际的TTS适配器
  TTS: PiperTTS
  # 记忆模块，默认不开启记忆；如果想使用超长记忆，推荐使用mem0ai；如果注重隐私，请使用本地的mem_local_short
  Memory: nomem
  # 意图识别模块开启后，可以播放音乐、控制音量、识别退出指令。
  # 不想开通意图识别，就设置成：nointent
  # 意图识别可使用intent_llm。优点：通用性强，缺点：增加串行前置意图识别模块，会增加处理时间，支持控制音量大小等iot操作
  # 意图识别可使用function_call，缺点：需要所选择的LLM支持function_call，优点：按需调用工具、速度快，理论上能全部操作所有iot指令
  # 默认免费的ChatGLMLLM就已经支持function_call，但是如果像追求稳定建议把LLM设置成：DoubaoLLM，使用的具体model_name是：doubao-1-5-pro-32k-250115
  Intent: function_call

# 意图识别，是用于理解用户意图的模块，例如：播放音乐
Intent:
  # 不使用意图识别
  nointent:
    # 不需要动type
    type: nointent
  intent_llm:
    # 不需要动type
    type: intent_llm
    # 配备意图识别独立的思考模型
    # 如果这里不填，则会默认使用selected_module.LLM的模型作为意图识别的思考模型
    # 如果你的不想使用selected_module.LLM意图识别，这里最好使用独立的LLM作为意图识别，例如使用免费的ChatGLMLLM
    llm: ChatGLMLLM
    # plugins_func/functions下的模块，可以通过配置，选择加载哪个模块，加载后对话支持相应的function调用
    # 系统默认已经记载"handle_exit_intent(退出识别)"、"play_music(音乐播放)"插件，请勿重复加载
    # 下面是加载查天气、角色切换、加载查新闻的插件示例
    functions:
      - get_weather
      - get_news_from_newsnow
      - play_music
  function_call:
    # 不需要动type
    type: function_call
    # plugins_func/functions下的模块，可以通过配置，选择加载哪个模块，加载后对话支持相应的function调用
    # 系统默认已经记载"handle_exit_intent(退出识别)"、"play_music(音乐播放)"插件，请勿重复加载
    # 下面是加载查天气、角色切换、加载查新闻的插件示例
    functions:
      - change_role
      - get_weather
      # - get_news_from_chinanews
      - get_news_from_newsnow
      # play_music是服务器自带的音乐播放，hass_play_music是通过home assistant控制的独立外部程序音乐播放
      # 如果用了hass_play_music，就不要开启play_music，两者只留一个
      - play_music
      #- hass_get_state
      #- hass_set_state
      #- hass_play_music

Memory:
  mem0ai:
    type: mem0ai
    # https://app.mem0.ai/dashboard/api-keys
    # 每月有1000次免费调用
    api_key: m0-cF9VnQ2NUjHL0E8RZ4C2WY9cHKG9EK00YF5tzOI2
  nomem:
    # 不想使用记忆功能，可以使用nomem
    type: nomem
  mem_local_short:
    # 本地记忆功能，通过selected_module的llm总结，数据保存在本地服务器，不会上传到外部服务器
    type: mem_local_short
    # 配备记忆存储独立的思考模型
    # 如果这里不填，则会默认使用selected_module.LLM的模型作为意图识别的思考模型
    # 如果你的不想使用selected_module.LLM记忆存储，这里最好使用独立的LLM作为意图识别，例如使用免费的ChatGLMLLM
    llm: ChatGLMLLM

ASR:
  ASR_FinnishWhisper:
    type: whisper_local
    model_dir: "models/whisper-tiny-finnish"
    output_dir: "tmp/"

VAD:
  SileroVAD:
    type: silero
    threshold: 0.5
    threshold_low: 0.3
    model_dir: models/snakers4_silero-vad
    min_silence_duration_ms: 200  # 如果说话停顿比较长，可以把这个值设置大一些

LLM:
  # 所有openai类型均可以修改超参，以AliLLM为例
  # 当前支持的type为openai、dify、ollama，可自行适配
  ChatGLMLLM:
    # 定义LLM API类型
    type: openai
    # glm-4-flash 是免费的，但是还是需要注册填写api_key的
    # 可在这里找到你的api key https://bigmodel.cn/usercenter/proj-mgmt/apikeys
    model_name: glm-4-flash
    url: https://open.bigmodel.cn/api/paas/v4/
    api_key: 35c70a0d18bc47c7890f25c27be1c52a.PwczHqWQaAbKEjRT
TTS:
  # 当前支持的type为edge、doubao，可自行适配
  PiperTTS:
    type: piper_tts
    model_dir: "models/piper_voices_fin"
    output_dir: "tmp/"
  MMSTTS:
    type: mms_tts
    model_dir: "models/mms-tts-fin"
    output_dir: "tmp/"